{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3fe765b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pickle\n",
    "from typing import Tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e12cfa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in /home/codespace/anaconda3/lib/python3.9/site-packages (16.1.0)\r\n",
      "Requirement already satisfied: numpy>=1.16.6 in /home/codespace/anaconda3/lib/python3.9/site-packages (from pyarrow) (1.21.5)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbcdb420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__\n",
    "\n",
    "\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "946de4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3136755c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation of trips duration in January (in minutes): 34.851053592192876\n",
      "Fraction of records left after dropping outliers: 0.9778326020432945\n",
      "Dimensionality of the feature matrix (number of columns): 518\n",
      "RMSE on the train data: 7.948999308349224\n"
     ]
    }
   ],
   "source": [
    "# Calculate 'duration' as the difference between drop-off and pick-up times\n",
    "df['duration'] = (df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime'])\n",
    "\n",
    "# Convert duration from timedelta to minutes\n",
    "df['duration_min'] = df['duration'].dt.total_seconds() / 60\n",
    "\n",
    "# Calculate the standard deviation of trip durations in January (in minutes)\n",
    "std_duration_january = df['duration_min'].std()\n",
    "print(\"Standard deviation of trips duration in January (in minutes):\", std_duration_january)\n",
    "\n",
    "# Filtering df to remove outliers, keeping only durations between 1 and 60 minutes\n",
    "original_count = len(df)\n",
    "df_filtered = df[(df['duration_min'] >= 1) & (df['duration_min'] <= 60)].copy()\n",
    "filtered_count = len(df_filtered)\n",
    "\n",
    "# Determine what fraction of records remains after dropping outliers\n",
    "fraction_left = filtered_count / original_count\n",
    "print(\"Fraction of records left after dropping outliers:\", fraction_left)\n",
    "\n",
    "# Convert location IDs to strings\n",
    "df_filtered['PULocationID'] = df_filtered['PULocationID'].astype(str)\n",
    "df_filtered['DOLocationID'] = df_filtered['DOLocationID'].astype(str)\n",
    "\n",
    "# Use only the filtered duration in minutes for further processing\n",
    "df_filtered['duration'] = df_filtered['duration_min']\n",
    "\n",
    "# Convert DataFrame to a list of dictionaries for feature encoding\n",
    "data_dicts = df_filtered[['PULocationID', 'DOLocationID']].to_dict(orient='records')\n",
    "\n",
    "# Create and apply DictVectorizer\n",
    "vectorizer = DictVectorizer(sparse=True)\n",
    "feature_matrix = vectorizer.fit_transform(data_dicts)\n",
    "\n",
    "# Number of columns in the feature matrix\n",
    "print(\"Dimensionality of the feature matrix (number of columns):\", feature_matrix.shape[1])\n",
    "\n",
    "# Target variable\n",
    "y = df_filtered['duration']\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_matrix, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the training data\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Calculate RMSE on the training data\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "print(\"RMSE on the train data:\", rmse_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "611c18c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as linear_regression_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model using pickle\n",
    "model_filename = 'linear_regression_model.pkl'\n",
    "with open(model_filename, 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "\n",
    "print(f\"Model saved as {model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21049be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer saved as vectorizer.pkl\n"
     ]
    }
   ],
   "source": [
    "#save the vectorizer too\n",
    "vectorizer_filename = 'vectorizer.pkl'\n",
    "with open(vectorizer_filename, 'wb') as file:\n",
    "    pickle.dump(vectorizer, file)\n",
    "\n",
    "print(f\"Vectorizer saved as {vectorizer_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6ab1b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "with open(model_filename, 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "\n",
    "# Load the saved vectorizer\n",
    "with open(vectorizer_filename, 'rb') as file:\n",
    "    loaded_vectorizer = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dacb18f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data loaded. Calculating duration...\n",
      "Filtering outliers...\n",
      "Converting location IDs to strings...\n",
      "Data preprocessing complete.\n",
      "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
      "0         2  2024-02-01 00:04:45   2024-02-01 00:19:58              1.0   \n",
      "1         2  2024-02-01 00:56:31   2024-02-01 01:10:53              1.0   \n",
      "2         2  2024-02-01 00:07:50   2024-02-01 00:43:12              2.0   \n",
      "3         1  2024-02-01 00:01:49   2024-02-01 00:10:47              1.0   \n",
      "4         1  2024-02-01 00:37:35   2024-02-01 00:51:15              1.0   \n",
      "\n",
      "   trip_distance  RatecodeID store_and_fwd_flag PULocationID DOLocationID  \\\n",
      "0           4.39         1.0                  N           68          236   \n",
      "1           7.71         1.0                  N           48          243   \n",
      "2          28.69         2.0                  N          132          261   \n",
      "3           1.10         1.0                  N          161          163   \n",
      "4           2.60         1.0                  N          246           79   \n",
      "\n",
      "   payment_type  ...  extra  mta_tax  tip_amount  tolls_amount  \\\n",
      "0             1  ...    1.0      0.5        1.28          0.00   \n",
      "1             1  ...    1.0      0.5        9.00          0.00   \n",
      "2             2  ...    0.0      0.5        0.00          6.94   \n",
      "3             1  ...    3.5      0.5        2.85          0.00   \n",
      "4             2  ...    3.5      0.5        0.00          0.00   \n",
      "\n",
      "   improvement_surcharge  total_amount  congestion_surcharge  Airport_fee  \\\n",
      "0                    1.0         26.78                   2.5         0.00   \n",
      "1                    1.0         45.00                   2.5         0.00   \n",
      "2                    1.0         82.69                   2.5         1.75   \n",
      "3                    1.0         17.15                   2.5         0.00   \n",
      "4                    1.0         20.60                   2.5         0.00   \n",
      "\n",
      "         duration duration_min  \n",
      "0 0 days 00:15:13    15.216667  \n",
      "1 0 days 00:14:22    14.366667  \n",
      "2 0 days 00:35:22    35.366667  \n",
      "3 0 days 00:08:58     8.966667  \n",
      "4 0 days 00:13:40    13.666667  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(data_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Preprocess the data from the given Parquet file.\n",
    "\n",
    "    Parameters:\n",
    "    data_path (str): Path to the input data file (Parquet format).\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Preprocessed DataFrame.\n",
    "    \"\"\"\n",
    "    print(\"Loading data...\")\n",
    "    df = pd.read_parquet(data_path)\n",
    "    print(\"Data loaded. Calculating duration...\")\n",
    "\n",
    "    df['duration'] = (df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime'])\n",
    "    df['duration_min'] = df['duration'].dt.total_seconds() / 60\n",
    "\n",
    "    print(\"Filtering outliers...\")\n",
    "    df_filtered = df[(df['duration_min'] >= 1) & (df['duration_min'] <= 60)].copy()\n",
    "\n",
    "    print(\"Converting location IDs to strings...\")\n",
    "    df_filtered['PULocationID'] = df_filtered['PULocationID'].astype(str)\n",
    "    df_filtered['DOLocationID'] = df_filtered['DOLocationID'].astype(str)\n",
    "\n",
    "    print(\"Data preprocessing complete.\")\n",
    "    return df_filtered\n",
    "\n",
    "data_path = 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-02.parquet'\n",
    "df_filtered = preprocess_data(data_path)\n",
    "print(df_filtered.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2d89dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vectorizer...\n",
      "Vectorizer loaded.\n",
      "Transforming data...\n",
      "Data transformed. Shape: (2938060, 518)\n"
     ]
    }
   ],
   "source": [
    "def load_vectorizer(vectorizer_path: str) -> DictVectorizer:\n",
    "    \"\"\"\n",
    "    Load the DictVectorizer from the given file.\n",
    "\n",
    "    Parameters:\n",
    "    vectorizer_path (str): Path to the saved DictVectorizer file (Pickle format).\n",
    "\n",
    "    Returns:\n",
    "    DictVectorizer: Loaded DictVectorizer.\n",
    "    \"\"\"\n",
    "    print(\"Loading vectorizer...\")\n",
    "    with open(vectorizer_path, 'rb') as file:\n",
    "        vectorizer = pickle.load(file)\n",
    "    print(\"Vectorizer loaded.\")\n",
    "    return vectorizer\n",
    "\n",
    "\n",
    "vectorizer_path = 'vectorizer.pkl'\n",
    "vectorizer = load_vectorizer(vectorizer_path)\n",
    "\n",
    "data_dicts = df_filtered[['PULocationID', 'DOLocationID']].to_dict(orient='records')\n",
    "print(\"Transforming data...\")\n",
    "X = vectorizer.transform(data_dicts)\n",
    "print(\"Data transformed. Shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "858c49e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Model loaded.\n",
      "Making predictions...\n",
      "Predictions made. First 10 predictions: [13.24544287 20.48169216 37.42164098 13.46284077 13.12928572 12.15326858\n",
      " 12.69852248 13.03233581 13.81530867 10.55141448]\n"
     ]
    }
   ],
   "source": [
    "def load_model(model_path: str) -> LinearRegression:\n",
    "    \"\"\"\n",
    "    Load the model from the given file.\n",
    "\n",
    "    Parameters:\n",
    "    model_path (str): Path to the saved model file (Pickle format).\n",
    "\n",
    "    Returns:\n",
    "    LinearRegression: Loaded model.\n",
    "    \"\"\"\n",
    "    print(\"Loading model...\")\n",
    "    with open(model_path, 'rb') as file:\n",
    "        model = pickle.load(file)\n",
    "    print(\"Model loaded.\")\n",
    "    return model\n",
    "\n",
    "# Example usage\n",
    "model_path = 'linear_regression_model.pkl'\n",
    "model = load_model(model_path)\n",
    "\n",
    "y = df_filtered['duration_min']\n",
    "print(\"Making predictions...\")\n",
    "y_pred = model.predict(X)\n",
    "print(\"Predictions made. First 10 predictions:\", y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "564d196a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating RMSE...\n",
      "RMSE calculated: 8.124017135620836\n"
     ]
    }
   ],
   "source": [
    "def calculate_rmse(y_true: pd.Series, y_pred: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the Root Mean Squared Error (RMSE).\n",
    "\n",
    "    Parameters:\n",
    "    y_true (pd.Series): True values.\n",
    "    y_pred (np.ndarray): Predicted values.\n",
    "\n",
    "    Returns:\n",
    "    float: RMSE value.\n",
    "    \"\"\"\n",
    "    print(\"Calculating RMSE...\")\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    print(\"RMSE calculated:\", rmse)\n",
    "    return rmse\n",
    "\n",
    "# Example usage\n",
    "rmse = calculate_rmse(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d5abd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
